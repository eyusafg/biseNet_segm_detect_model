# 训练速度优化说明

## 已实施的优化

### 1. ✅ 启用混合精度训练（FP16）
**改动**: `use_fp16=False` → `use_fp16=True`

**效果**: 
- 训练速度提升约 **2倍**
- GPU内存占用减少约 **50%**
- 可以支持更大的batch_size

**注意**: 
- 需要GPU支持FP16（大多数现代GPU都支持）
- 精度损失通常很小（<1%）

### 2. ✅ 优化DataLoader配置
**新增配置项**:
```python
num_workers=8,              # 数据加载进程数（建议设置为CPU核心数）
pin_memory=True,            # 加速GPU传输
persistent_workers=True,    # 保持worker进程，减少重启开销
prefetch_factor=2,          # 每个worker预取的batch数
```

**效果**:
- `num_workers=8`: 并行加载数据，充分利用CPU
- `pin_memory=True`: 数据直接传输到GPU，减少CPU-GPU拷贝时间
- `persistent_workers=True`: 避免每个epoch重启worker，减少开销
- `prefetch_factor=2`: 提前准备数据，减少等待时间

**建议**:
- `num_workers` 设置为CPU核心数的一半到全部（但不超过16）
- 如果内存充足，可以增加 `prefetch_factor` 到 3-4

### 3. ✅ 修复cudnn设置
**改动**: `torch.backends.cudnn.deterministic = True` → `False`

**效果**:
- 允许cudnn自动选择最优算法
- 训练速度提升约 **5-10%**

**注意**: 
- 会牺牲完全可复现性（每次运行结果可能略有不同）
- 如果不需要完全可复现，建议保持为False

### 4. ✅ 添加梯度累积支持
**新增配置项**: `gradient_accumulation_steps=1`

**用途**:
- 如果内存限制batch_size，可以通过梯度累积模拟更大的batch
- 例如：batch_size=32, gradient_accumulation_steps=2 等价于 batch_size=64

**效果**:
- 允许使用更大的"有效batch_size"
- 训练更稳定，收敛更好
- 不增加内存占用

**使用示例**:
```python
# 如果内存只能支持batch_size=32，但想用64的效果
ims_per_gpu=32
gradient_accumulation_steps=2  # 等价于batch_size=64
```

### 5. ✅ 提高batch_size上限
**改动**: `ims_per_gpu=32` → `64`

**效果**:
- 如果内存允许，更大的batch_size可以提升训练速度
- GPU利用率更高

**注意**: 
- 如果内存不足，可以降低batch_size并配合梯度累积

## 性能提升预期

### 综合效果
- **训练速度**: 提升约 **2-3倍**
- **GPU利用率**: 从可能50-60%提升到80-90%+
- **数据加载**: 从可能的瓶颈变为非瓶颈

### 具体提升
1. **FP16**: ~2倍速度提升
2. **DataLoader优化**: ~20-30%速度提升
3. **cudnn优化**: ~5-10%速度提升
4. **更大batch_size**: ~10-20%速度提升（如果内存允许）

## 配置建议

### 高性能配置（推荐）
```python
ims_per_gpu=64
num_workers=8              # 根据CPU核心数调整
pin_memory=True
persistent_workers=True
prefetch_factor=2
use_fp16=True
gradient_accumulation_steps=1
```

### 内存受限配置
```python
ims_per_gpu=32             # 降低batch_size
num_workers=8
pin_memory=True
persistent_workers=True
prefetch_factor=2
use_fp16=True
gradient_accumulation_steps=2  # 通过梯度累积模拟batch_size=64
```

### 极致性能配置（如果硬件允许）
```python
ims_per_gpu=128            # 更大的batch_size
num_workers=16              # 更多worker
pin_memory=True
persistent_workers=True
prefetch_factor=4          # 更多预取
use_fp16=True
gradient_accumulation_steps=1
```

## 进一步优化建议

### 1. 数据预处理优化128
如果数据加载仍然是瓶颈，可以考虑：
- **预计算距离图**: 如果使用PointRend，可以预先计算并保存距离图
- **数据缓存**: 将处理后的数据缓存到内存或SSD
- **数据格式优化**: 使用更快的图像格式（如HDF5）

### 2. 模型优化
- **减少不必要的计算**: 检查是否有冗余的前向传播
- **使用torch.compile()**: PyTorch 2.0+可以编译模型，提升速度

### 3. 硬件优化
- **使用NVMe SSD**: 如果数据在HDD上，迁移到SSD可以显著提升加载速度
- **增加内存**: 如果数据可以完全加载到内存，可以设置`num_workers=0`并预加载

### 4. 训练策略优化
- **减少评估频率**: 如果评估很慢，可以减少评估次数
- **使用更少的评估尺度**: 减少`eval_scales`的数量
- **早停策略**: 如果收敛很快，可以提前停止

## 监控和调试

### 检查数据加载是否仍是瓶颈
```python
# 在训练循环中添加时间统计
import time
data_time = 0
train_time = 0

for it, batch in enumerate(dl):
    t0 = time.time()
    # ... 数据加载 ...
    data_time += time.time() - t0
    
    t0 = time.time()
    # ... 训练步骤 ...
    train_time += time.time() - t0

print(f"数据加载时间: {data_time:.2f}s, 训练时间: {train_time:.2f}s")
```

### 如果数据加载时间 > 训练时间
- 增加 `num_workers`
- 增加 `prefetch_factor`
- 检查数据预处理是否太慢
- 考虑预计算或缓存

### 如果GPU利用率 < 80%
- 增加 `batch_size`（如果内存允许）
- 增加 `num_workers`
- 检查是否有CPU-GPU同步点（如`.item()`, `.cpu()`等）

## 注意事项

1. **num_workers设置**: 
   - 不要设置过大（>16通常没有意义）
   - 如果内存不足，减少num_workers
   - Windows系统可能需要设置`persistent_workers=False`

2. **FP16稳定性**:
   - 如果训练不稳定，可以降低学习率
   - 或者使用`torch.cuda.amp.GradScaler`的默认设置

3. **梯度累积**:
   - 确保`gradient_accumulation_steps`能整除每个epoch的batch数
   - 学习率可能需要相应调整（通常不需要）

4. **内存监控**:
   - 使用`nvidia-smi`监控GPU内存
   - 如果OOM，降低batch_size或增加gradient_accumulation_steps

